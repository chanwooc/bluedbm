
\section{Related Work}
\label{sec:related}

%Modern analytics systems are usually built as a cluster of homogeneous machines
%networked using a fast interconnect. In such a configuration, the system can
%perform at its full potential if the dataset can fit in its collective DRAM.

In Big Data scale workloads, building a cluster with enough DRAM capacity to
accommodate the entire dataset can be very desirable but expensive. An example
of such a system is RAMCloud, which is a DRAM-based storage for large-scale
datacenter applications~\cite{ramcloud, rumble_log_dram}.  RAMCloud provides more than 64TBs of DRAM
storage distributed across over 1000 servers networked over high-speed
interconnect. Although RAMCloud provides 100 to 1000 times better performance
than disk-based systems of similar scale, its high energy consumption and high
price per GB limits its widespread use except for extremely performance and
latency sensitive workloads.

NAND-Flash-based SSD devices are gaining traction as a faster alternative to
disks, and close the performance gap between DRAM and persistent storage.
SSDs have the benefit of an order of magnitude cheaper price compared to DRAM,
and an order of magnitude faster performance compared to disk.
Several SSD-optimized analytics softwares, such as the SanDisk
Zetascale~\cite{zetascale} have demonstrated promising
performance while using SSD has the primary data storage.
Many commercial SSD devices have adopted high-performance PCIe interface in
order to overcome the slower SATA bus interface designed for
disk~\cite{fusionio, violinmemory, intelnvme}. Attempts to
use flash as a persistent DRAM alternative by plugging it into a RAM slot
are being explored as well~\cite{diablotechnology}. 

SSD storage devices have been largely developed to be a faster drop-in
replacement for disk drives. This backwards compatibility helped them gain
widespread adoption.  However, this required additional software and hardware to
hide the difference in device characteristics.  Due to the high performance of
SSDs, even inefficiencies in the storage management software becomes
significant, and optimizing such software has been under active investigation.
Moneta~\cite{ucsd_moneta} modifies the operating system's storage management
components to reduce software overhead when accessing NVM storage devices.
Willow~\cite{ucsd_willow} provides an easy way to augment SSD controllers with
additional interface semantics that make better use of SSD characteristics, in
addition to a backwards compatible storage interface.  Due to the high
performance of SSDs, even the software stack QuickSAN~\cite{ucsd_quicksan} is an
attempt to remove a layer of software overhead by augmenting the storage device
with a low-latency NIC, so that remote storage access does not need to go
through a separate network software stack.

Another important attempt to accelerate SSD storage performance is in-storage
processing, where some data analytics is offloaded to embedded processors inside
SSDs. These processors have extremely low-latency access to storage, and helped
overcome the limitations of the storage interface bus. The idea of in-storage
processing itself is not new. The idea of intelligent disks (IDISK) connected to
each other using serial networks have been proposed in 1998~\cite{idisk}, and
adding processor to disk heads to do simple filters have been suggested as early
as in the 1970s~\cite{?,?,?}. However, performance improvements of such special
purpose hardware did not justify their price at the time. This idea is seeing
new light with advancement of fast flash devices. This idea is seeing new light
with the advancement of fast flash technology. Devices such as Smart
SSDS~\cite{smartssdquery,smartssdcost,ucsd_willow} and Programmable
SSDs~\cite{xsd} have been investigated and showed promising results. Because of
the limited performance of embedded processors on such power-constrained
devices, embedding reconfigurable hardware on storage devices are being
investigated as well. Ibex~\cite{ibex} is a MySQL accelerator platform where a
SATA SSD is coupled with an FPGA. Relational operators such as selection and
group-by are performed on the FPGA whenever possible, otherwise they are
forwarded to software. On the other end of the spectrum, systems such as
XSD~\cite{xsd} embeds a GPU into a SSD controller, and demonstrates high
performance accelerating MapReduce.

Building specialized hardware for databases have been extensively studied and
productized. Companies such as Oracle~\cite{exadata} and
IBM/Netezza~\cite{netezza} have used FPGAs to offload database queries.
FPGAs have been used to accelerate operations such as hash index
lookups~\cite{walkers}. Domain-specific processors for database queries are
recently being developed, such as Q100~\cite{q100} and LINQits~\cite{linqits}.
Q100 is a data-flow style processor with an instruction set architecture that
supported SQL queries. LINQits mapped a query language called LINQ to a set of
accelerated hardware templates on a heterogeneous SoC (FPGA + ARM). Both designs
exhibited order of magnitude performance gains at lower power, affirming that
specialized hardware for data processing is very advantageous.
%However, in both cases, experiments were
%conducted with data that is on-chip or in DRAM.
Some database accelerators benefit from being on the datapath of normal data
movement. Accelerators have been place in-path to extract meta-data such as
histograms of tables without additional overhead.

Incorporating reconfigurable hardware accelerators into large datacenters are
being actively investigates as well. Microsoft recently has built and
demonstrated the power/performance benefits of a FPGA-based system called
Catapult~\cite{msr_catapult}.  Catapult uses a large number of homogeneous
servers each augmented with an FPGA.  The FPGAs form a network among themselves
via high-speed serial links so that large jobs can be mapped to groups of FPGAs.
Catapult was demonstrated to deliver much faster performance while consuming
less power, compared to a normal ram cloud cluster. FlashBoost has similar
goals in terms of reconfigurable hardware acceleration, but it uses flash
devices to accelerate lower cost systems that do not have enough collective DRAM
to host the entire dataset.

FlashBoost incorporates ideas such as in-storage processing and integrated
networks to construct a high-performance flash-based analytics appliance.
Previous work such as BlueDBM~\cite{bluedbm} have demonstrated the feasibility
of such an approach at a small scale, but the system described in BlueDBM was
too small and slow to accurately evaluate its benefits and trade-offs with
real-world problems.  FlashBoost presents a system with modern components and
sufficient capacity to handle Big Data problems.
